{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a neural network on the MNIST Fashion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and create dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Dataset\n",
    "We can index Datasets manually like a list: `training_data[index]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape:  torch.Size([1, 28, 28])\n",
      "img.dtype:  torch.float32\n",
      "img.device:  cpu\n",
      "im1.shape: torch.Size([28, 28])\n",
      "im2.shape:  torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "sample_idx = 108\n",
    "\n",
    "img, label = training_data[sample_idx]\n",
    "print('img.shape: ',  img.shape)\n",
    "print('img.dtype: ',  img.dtype)\n",
    "print('img.device: ', img.device) # Notice that the data is lying on the CPU. This is standard.\n",
    "\n",
    "im1 = img.squeeze()\n",
    "print('im1.shape:', im1.size())\n",
    "im2 = im1.unsqueeze(0)\n",
    "print('im2.shape: ', im2.shape)\n",
    "\n",
    "plt.title(labels_map[label], fontsize=20)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders\n",
    "The `Dataset` retrieves our dataset’s features and labels one sample at a time. When training a model, we typically want to pass samples in “minibatches” and reshuffle the data at every epoch to reduce model overfitting and use Python’s `multiprocessing` to speed up data retrieval.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "shuffle=True\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=shuffle)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Iterate through the DataLoader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_input, train_labels = next(iter(train_dataloader)) # Convert to iterable and get next element\n",
    "print(f\"Input batch shape: {train_input.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_input[0].squeeze()\n",
    "label = int(train_labels[0])\n",
    "\n",
    "plt.title(labels_map[label], fontsize=20)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 60, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(60, 15, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (3): ReLU()\n",
      "  (4): Flatten(start_dim=1, end_dim=-1)\n",
      "  (5): Linear(in_features=540, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=1, out_channels=60, kernel_size=3, stride=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=60, out_channels=15, kernel_size=3,stride=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=540, out_features=10, bias=True)\n",
    "    )\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.optim' has no attribute 'SDG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3258183/2207870670.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Define the loss funciton. It does not expect the input to be normalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSDG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Choose the optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Move model parameters to the device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.optim' has no attribute 'SDG'"
     ]
    }
   ],
   "source": [
    "# Define a few hyperparameters\n",
    "device = torch.device('cuda')\n",
    "epochs = 5 # Number of iterations with stochastic gradient descent.\n",
    "learning_rate = 0.003\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # Define the loss funciton. It does not expect the input to be normalized\n",
    "optimizer = torch.optim.SDG(model.parameters(), lr=learning_rate) # Choose the optimizer \n",
    "model = model.to(device) # Move model parameters to the device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the train loop\n",
    "\n",
    "Inside the training loop, optimization happens in three steps:\n",
    " * Call `optimizer.zero_grad()` to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
    " * Backpropagate the prediction loss with a call to `loss.backward()`. PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
    " * Once we have our gradients, we call `optimizer.step()` to adjust the parameters by the gradients collected in the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, loss_fn, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    batch = 0\n",
    "    for x, y in dataloader:\n",
    "        # Compute prediction and loss\n",
    "        batch = batch + 1\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(x)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def validation_epoch(dataloader, model, loss_fn, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    val_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            \n",
    "            val_loss += loss_fn(pred, y).item() # This is a float\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum()\n",
    "\n",
    "    val_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Validataion Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {val_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_epoch(train_dataloader, model, loss_fn, optimizer, device)\n",
    "    validation_epoch(test_dataloader, model, loss_fn, device)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
